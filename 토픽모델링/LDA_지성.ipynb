{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('type_classification_tokens.csv', names=['index', 'product', 'score', 'skin_type', 'reviews','tokens','tokens(1)'], header=None, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('tokens(1)',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연속단어 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntag_list = ['NNP','NNG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntoken_list = [[token[0] for token in tokens if token[1] in Ntag_list] for tokens in df['tokens']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Ntoken_list)):\n",
    "    j=0\n",
    "    while j < len(Ntoken_list[i])-2:\n",
    "        if Ntoken_list[i][j] == '아' and Ntoken_list[i][j+1] == '벤' and Ntoken_list[i][j+1] == '느':\n",
    "            Ntoken_list[i][j] = '아벤느'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '리얼' and Ntoken_list[i][j+1] == '베리' and Ntoken_list[i][j+1] == '어':\n",
    "            Ntoken_list[i][j] = '리얼베리어'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '리' and Ntoken_list[i][j+1] == '뉴' and Ntoken_list[i][j+1] == '얼':\n",
    "            Ntoken_list[i][j] = '리뉴얼'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '바이오' and Ntoken_list[i][j+1] == '힐' and Ntoken_list[i][j+1] == '보':\n",
    "            Ntoken_list[i][j] = '바이오힐보'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '톤' and Ntoken_list[i][j+1] == '업' and Ntoken_list[i][j+1] == '크림':\n",
    "            Ntoken_list[i][j] = '톤업크림'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '쿠' and Ntoken_list[i][j+1] == '링' and Ntoken_list[i][j+1] == '감':\n",
    "            Ntoken_list[i][j] = '쿨링감'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '라' and Ntoken_list[i][j+1] == '로슈' and Ntoken_list[i][j+1] == '포':\n",
    "            Ntoken_list[i][j] = '라로슈포'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '아토' and Ntoken_list[i][j+1] == '베리' and Ntoken_list[i][j+1] == '어':\n",
    "            Ntoken_list[i][j] = '아토베리어'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '수분' and Ntoken_list[i][j+1] == '부족' and Ntoken_list[i][j+1] == '지성':\n",
    "            Ntoken_list[i][j] = '수부지'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '라마' and Ntoken_list[i][j+1] == '이' and Ntoken_list[i][j+1] == '딘':\n",
    "            Ntoken_list[i][j] = '세라마이딘'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '피부' and Ntoken_list[i][j+1] == '진정' and Ntoken_list[i][j+1] == '효과':\n",
    "            Ntoken_list[i][j] = '진정'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '바이오' and Ntoken_list[i][j+1] == '더' and Ntoken_list[i][j+1] == '마':\n",
    "            Ntoken_list[i][j] = '바이오더마'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '보' and Ntoken_list[i][j+1] == '타' and Ntoken_list[i][j+1] == '닉':\n",
    "            Ntoken_list[i][j] = '보타닉'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '민' and Ntoken_list[i][j+1] == '감성' and Ntoken_list[i][j+1] == '피부':\n",
    "            Ntoken_list[i][j] = '민감성'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '닥터' and Ntoken_list[i][j+1] == '자르' and Ntoken_list[i][j+1] == '카':\n",
    "            Ntoken_list[i][j] = '닥터자르카'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '악' and Ntoken_list[i][j+1] == '건성' and Ntoken_list[i][j+1] == '피부':\n",
    "            Ntoken_list[i][j] = '악건성피부'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '지' and Ntoken_list[i][j+1] == '복합성' and Ntoken_list[i][j+1] == '피부':\n",
    "            Ntoken_list[i][j] = '지복합성피부'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '베리' and Ntoken_list[i][j+1] == '어' and Ntoken_list[i][j+1] == '익스트림':\n",
    "            Ntoken_list[i][j] = '베리어익스트림'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '자작나무' and Ntoken_list[i][j+1] == '수분' and Ntoken_list[i][j+1] == '크림':\n",
    "            Ntoken_list[i][j] = '자작나무수분크림'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '닥터' and Ntoken_list[i][j+1] == '디' and Ntoken_list[i][j+1] == '런':\n",
    "            Ntoken_list[i][j] = '닥터디런'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '화' and Ntoken_list[i][j+1] == '농성' and Ntoken_list[i][j+1] == '여드름':\n",
    "            Ntoken_list[i][j] = '화농성여드름'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif Ntoken_list[i][j] == '자르' and Ntoken_list[i][j+1] == '카' and Ntoken_list[i][j+1] == '페어':\n",
    "            Ntoken_list[i][j] = '자르카페어'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '히루론산':\n",
    "            Ntoken_list[i][j] = '히알루론산'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '블레미쉬':\n",
    "            Ntoken_list[i][j] = '블레미쉬'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '유수분밸런스':\n",
    "            Ntoken_list[i][j] = '유수분밸런스'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '히루론산':\n",
    "            Ntoken_list[i][j] = '히알루론산'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '차앤박':\n",
    "            Ntoken_list[i][j] = '차앤박'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '리페어크림':\n",
    "            Ntoken_list[i][j] = '리페어크림'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '세라마이드':\n",
    "            Ntoken_list[i][j] = '세라마이드'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '원플러스원':\n",
    "            Ntoken_list[i][j] = '원플러스원'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '피부장벽강화':\n",
    "            Ntoken_list[i][j] = '피부장벽강화'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '판테시':\n",
    "            Ntoken_list[i][j] = '판테놀'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '모든피부타입':\n",
    "            Ntoken_list[i][j] = '모든피부타입'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '힐판테':\n",
    "            Ntoken_list[i][j] = '판테놀'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1] + Ntoken_list[i][j+2]) == '부승관':\n",
    "            Ntoken_list[i][j] = '부승관'\n",
    "            del Ntoken_list[i][j+1:j+3]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Ntoken_list)):\n",
    "    j=0\n",
    "    while j < len(Ntoken_list[i])-1:\n",
    "        if Ntoken_list[i][j] == '수분' and Ntoken_list[i][j+1] == '크림':\n",
    "            Ntoken_list[i][j] = '수분크림'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '수분' and Ntoken_list[i][j+1] == '감':\n",
    "            Ntoken_list[i][j] = '수분감'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '유' and Ntoken_list[i][j+1] == '분기':\n",
    "            Ntoken_list[i][j] = '유분기'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '올리브' and Ntoken_list[i][j+1] == '영':\n",
    "            Ntoken_list[i][j] = '올리브영'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '진정' and Ntoken_list[i][j+1] == '효과':\n",
    "            Ntoken_list[i][j] = '진정효과'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '속' and Ntoken_list[i][j+1] == '건조':\n",
    "            Ntoken_list[i][j] = '속건조'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '보습' and Ntoken_list[i][j+1] == '감':\n",
    "            Ntoken_list[i][j] = '보습감'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '구매' and Ntoken_list[i][j+1] == '의사':\n",
    "            Ntoken_list[i][j] = '구매의사'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '발림' and Ntoken_list[i][j+1] == '성도':\n",
    "            Ntoken_list[i][j] = '발림성'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '사용' and Ntoken_list[i][j+1] == '감':\n",
    "            Ntoken_list[i][j] = '사용감'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '젤' and Ntoken_list[i][j+1] == '크림':\n",
    "            Ntoken_list[i][j] = '젤크림'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '악' and Ntoken_list[i][j+1] == '건성':\n",
    "            Ntoken_list[i][j] = '악건성'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '톤' and Ntoken_list[i][j+1] == '업':\n",
    "            Ntoken_list[i][j] = '톤업'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '체험' and Ntoken_list[i][j+1] == '단':\n",
    "            Ntoken_list[i][j] = '체험단'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '재생' and Ntoken_list[i][j+1] == '크림':\n",
    "            Ntoken_list[i][j] = '재생크림'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '멀티' and Ntoken_list[i][j+1] == '밤':\n",
    "            Ntoken_list[i][j] = '멀티밤'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '쿠' and Ntoken_list[i][j+1] == '링':\n",
    "            Ntoken_list[i][j] = '쿨링'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '강' and Ntoken_list[i][j+1] == '추':\n",
    "            Ntoken_list[i][j] = '강추'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '좁쌀' and Ntoken_list[i][j+1] == '여드름':\n",
    "            Ntoken_list[i][j] = '좁쌀여드름'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '배' and Ntoken_list[i][j+1] == '송':\n",
    "            Ntoken_list[i][j] = '배송'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '속' and Ntoken_list[i][j+1] == '당김':\n",
    "            Ntoken_list[i][j] = '속당김'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '극' and Ntoken_list[i][j+1] == '건성':\n",
    "            Ntoken_list[i][j] = '극건성'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '젤' and Ntoken_list[i][j+1] == '타입':\n",
    "            Ntoken_list[i][j] = '젤타입'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif Ntoken_list[i][j] == '피부' and Ntoken_list[i][j+1] == '타입':\n",
    "            Ntoken_list[i][j] = '피부타입'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '시카':\n",
    "            Ntoken_list[i][j] = '시카'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '제품사용':\n",
    "            Ntoken_list[i][j] = '제품사용'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '화장솜':\n",
    "            Ntoken_list[i][j] = '화장솜'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '에스트라':\n",
    "            Ntoken_list[i][j] = '에스트라'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '스킨케어':\n",
    "            Ntoken_list[i][j] = '스킨케어'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '무향':\n",
    "            Ntoken_list[i][j] = '무향'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '피지오':\n",
    "            Ntoken_list[i][j] = '피지오'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '피부결':\n",
    "            Ntoken_list[i][j] = '피부결'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '스킨팩':\n",
    "            Ntoken_list[i][j] = '스킨팩'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '티트리':\n",
    "            Ntoken_list[i][j] = '티트리'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '화장전':\n",
    "            Ntoken_list[i][j] = '화장전'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '세안후':\n",
    "            Ntoken_list[i][j] = '세안후'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '물제형':\n",
    "            Ntoken_list[i][j] = '물제형'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '보습감':\n",
    "            Ntoken_list[i][j] = '보습감'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '수분부족':\n",
    "            Ntoken_list[i][j] = '수분부족'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '사용후':\n",
    "            Ntoken_list[i][j] = '사용후'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '보습크림':\n",
    "            Ntoken_list[i][j] = '보습크림'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '남자친구':\n",
    "            Ntoken_list[i][j] = '남자친구'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '바이오힐':\n",
    "            Ntoken_list[i][j] = '바이오힐'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '수분충전':\n",
    "            Ntoken_list[i][j] = '수분충전'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '유튜브':\n",
    "            Ntoken_list[i][j] = '유튜브'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '수분감도':\n",
    "            Ntoken_list[i][j] = '수분감'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '피부장벽':\n",
    "            Ntoken_list[i][j] = '피부장벽'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '레이어링':\n",
    "            Ntoken_list[i][j] = '레이어링'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '선크림':\n",
    "            Ntoken_list[i][j] = '선크림'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        elif str(Ntoken_list[i][j] + Ntoken_list[i][j+1]) == '가격대비':\n",
    "            Ntoken_list[i][j] = '가격대비'\n",
    "            del Ntoken_list[i][j+1]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = pd.read_csv('stopwords.txt', header=None)\n",
    "stopwords_list = stop_words[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Ntoken_list)):\n",
    "    Ntoken_list[i] = [j for j in Ntoken_list[i] if j not in stopwords_list and len(j)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['아벤느','리얼베리어','바이오힐보','라로슈포','아토베리어','바이오더마','보타닉','닥터자르카','베리어익스트림',\n",
    "             '자작나무수분크림','닥터디런','자르카페어','올리브영','멀티밤','블레미쉬','차앤박','리페어크림','올리브영',\n",
    "             '에스트라','피지오','바이오힐']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Ntoken_list)):\n",
    "    Ntoken_list[i] = [j for j in Ntoken_list[i] if j not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Ntoken.csv','w', newline='') as f :\n",
    "    write = csv.writer(f)\n",
    "    write.writerows(Ntoken_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ntoken_review'] = Ntoken_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None    65981\n",
       "복합성     12655\n",
       "건성       7845\n",
       "지성       3941\n",
       "Name: skin_type, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['skin_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "oily_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "oily_list=df['Ntoken_review'].loc[df['skin_type']==\"지성\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.callbacks import CoherenceMetric\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_topics 4개 이상~9이하  \n",
    "eta, alpha : auto  \n",
    "chunk_size : 타입별 문서/10  \n",
    "iterations : 100  \n",
    "passes : 20  \n",
    "no_above : 0.4, 0.5, 0.6  \n",
    "no_below : 50  \n",
    "coherece : c_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_param = [0.4,0.5,0.6]\n",
    "topic_param = [4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oily_list)//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45868620075571975\n",
      "0.4836144327120935\n",
      "0.4870066640291038\n",
      "0.4883853969842802\n",
      "0.5030366723212792\n",
      "0.5053729990428004\n",
      "0.5160789392665225\n",
      "0.5174139641356046\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "max_co = 0\n",
    "max_idx= 0\n",
    "\n",
    "for a in above_param:\n",
    "    dictionary = corpora.Dictionary(oily_list)\n",
    "    dictionary.filter_extremes(no_below=50, no_above=a)\n",
    "    bow_corpus = [dictionary.doc2bow(text) for text in oily_list]\n",
    "        \n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "    \n",
    "    for t in topic_param:\n",
    "        set={}\n",
    "        lda_model_tfidf = gensim.models.LdaMulticore(corpus=corpus_tfidf, num_topics=t, id2word=dictionary, passes=20, iterations=100, chunksize=394, random_state=42)\n",
    "        coherencemodel = CoherenceModel(model=lda_model_tfidf, texts=oily_list, dictionary=dictionary, coherence='c_v')\n",
    "        co_val = coherencemodel.get_coherence()\n",
    "                \n",
    "        set[\"no_above\"] = a\n",
    "        set[\"model\"] = lda_model_tfidf\n",
    "        set[\"topic_num\"] = t\n",
    "        set[\"co_val\"] = co_val\n",
    "        \n",
    "        grid_search.append(set)\n",
    "            \n",
    "        if co_val > max_co:\n",
    "            max_co = co_val\n",
    "            print (max_co)\n",
    "            max_idx = i\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = pd.DataFrame(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_above</th>\n",
       "      <th>model</th>\n",
       "      <th>topic_num</th>\n",
       "      <th>co_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=6, decay=0....</td>\n",
       "      <td>6</td>\n",
       "      <td>0.517414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=8, decay=0....</td>\n",
       "      <td>8</td>\n",
       "      <td>0.516200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=9, decay=0....</td>\n",
       "      <td>9</td>\n",
       "      <td>0.516079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=9, decay=0....</td>\n",
       "      <td>9</td>\n",
       "      <td>0.513808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=6, decay=0....</td>\n",
       "      <td>6</td>\n",
       "      <td>0.505373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=7, decay=0....</td>\n",
       "      <td>7</td>\n",
       "      <td>0.503284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=5, decay=0....</td>\n",
       "      <td>5</td>\n",
       "      <td>0.503037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=8, decay=0....</td>\n",
       "      <td>8</td>\n",
       "      <td>0.503018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=5, decay=0....</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.499180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=8, decay=0....</td>\n",
       "      <td>8</td>\n",
       "      <td>0.488385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=9, decay=0....</td>\n",
       "      <td>9</td>\n",
       "      <td>0.488297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=7, decay=0....</td>\n",
       "      <td>7</td>\n",
       "      <td>0.487445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=7, decay=0....</td>\n",
       "      <td>7</td>\n",
       "      <td>0.487007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=5, decay=0....</td>\n",
       "      <td>5</td>\n",
       "      <td>0.483614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=6, decay=0....</td>\n",
       "      <td>6</td>\n",
       "      <td>0.477992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.458686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_above                                              model  topic_num  \\\n",
       "15       0.6  LdaModel(num_terms=277, num_topics=6, decay=0....          6   \n",
       "17       0.6  LdaModel(num_terms=277, num_topics=8, decay=0....          8   \n",
       "12       0.5  LdaModel(num_terms=276, num_topics=9, decay=0....          9   \n",
       "18       0.6  LdaModel(num_terms=277, num_topics=9, decay=0....          9   \n",
       "9        0.5  LdaModel(num_terms=276, num_topics=6, decay=0....          6   \n",
       "10       0.5  LdaModel(num_terms=276, num_topics=7, decay=0....          7   \n",
       "8        0.5  LdaModel(num_terms=276, num_topics=5, decay=0....          5   \n",
       "11       0.5  LdaModel(num_terms=276, num_topics=8, decay=0....          8   \n",
       "14       0.6  LdaModel(num_terms=277, num_topics=5, decay=0....          5   \n",
       "13       0.6  LdaModel(num_terms=277, num_topics=4, decay=0....          4   \n",
       "5        0.4  LdaModel(num_terms=272, num_topics=8, decay=0....          8   \n",
       "6        0.4  LdaModel(num_terms=272, num_topics=9, decay=0....          9   \n",
       "16       0.6  LdaModel(num_terms=277, num_topics=7, decay=0....          7   \n",
       "4        0.4  LdaModel(num_terms=272, num_topics=7, decay=0....          7   \n",
       "7        0.5  LdaModel(num_terms=276, num_topics=4, decay=0....          4   \n",
       "2        0.4  LdaModel(num_terms=272, num_topics=5, decay=0....          5   \n",
       "3        0.4  LdaModel(num_terms=272, num_topics=6, decay=0....          6   \n",
       "0        0.4  LdaModel(num_terms=272, num_topics=4, decay=0....          4   \n",
       "1        0.4  LdaModel(num_terms=272, num_topics=4, decay=0....          4   \n",
       "\n",
       "      co_val  \n",
       "15  0.517414  \n",
       "17  0.516200  \n",
       "12  0.516079  \n",
       "18  0.513808  \n",
       "9   0.505373  \n",
       "10  0.503284  \n",
       "8   0.503037  \n",
       "11  0.503018  \n",
       "14  0.500642  \n",
       "13  0.499180  \n",
       "5   0.488385  \n",
       "6   0.488297  \n",
       "16  0.487445  \n",
       "4   0.487007  \n",
       "7   0.486807  \n",
       "2   0.483614  \n",
       "3   0.477992  \n",
       "0   0.460600  \n",
       "1   0.458686  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.sort_values(by='co_val', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.028*\"크림\" + 0.027*\"톤업\" + 0.020*\"사용\" + 0.019*\"마스크\" + 0.017*\"제품\" + 0.016*\"라인\" + 0.016*\"피부\" + 0.015*\"튜브\" + 0.014*\"앰플\" + 0.014*\"구매\" + 0.013*\"테노\" + 0.013*\"자연\" + 0.012*\"요즘\" + 0.012*\"진정효과\" + 0.011*\"트러블\" + 0.011*\"느낌\" + 0.010*\"이드\" + 0.010*\"위생\" + 0.010*\"베이스\" + 0.010*\"진정\"\n",
      "Topic: 1 Word: 0.032*\"여드름\" + 0.023*\"피부\" + 0.020*\"좁쌀\" + 0.020*\"진정\" + 0.017*\"크림\" + 0.017*\"제품\" + 0.017*\"기름\" + 0.016*\"보습\" + 0.015*\"지성\" + 0.014*\"사용\" + 0.014*\"느낌\" + 0.014*\"트러블\" + 0.014*\"자극\" + 0.012*\"아침\" + 0.012*\"저녁\" + 0.012*\"로션\" + 0.012*\"얼굴\" + 0.011*\"기름기\" + 0.011*\"베리\" + 0.011*\"추천\"\n",
      "Topic: 2 Word: 0.024*\"세일\" + 0.021*\"가격\" + 0.021*\"구매\" + 0.020*\"닥터\" + 0.019*\"수분크림\" + 0.018*\"제품\" + 0.016*\"크림\" + 0.015*\"사용\" + 0.014*\"피부\" + 0.013*\"할인\" + 0.012*\"보습\" + 0.011*\"자르\" + 0.011*\"추천\" + 0.011*\"지성\" + 0.011*\"화장전\" + 0.011*\"쿨링\" + 0.010*\"용량\" + 0.010*\"진정\" + 0.010*\"생각\" + 0.010*\"느낌\"\n",
      "Topic: 3 Word: 0.023*\"제품\" + 0.021*\"수분\" + 0.018*\"수분크림\" + 0.017*\"사용\" + 0.017*\"수부지\" + 0.017*\"크림\" + 0.017*\"피부\" + 0.017*\"느낌\" + 0.014*\"지성\" + 0.013*\"자극\" + 0.013*\"구매\" + 0.013*\"타입\" + 0.013*\"구입\" + 0.013*\"트러블\" + 0.012*\"여드름\" + 0.012*\"얼굴\" + 0.011*\"제가\" + 0.011*\"마무리\" + 0.010*\"건조\" + 0.010*\"만족\"\n",
      "Topic: 4 Word: 0.026*\"겨울\" + 0.025*\"지성\" + 0.023*\"피부\" + 0.022*\"건조\" + 0.022*\"보습\" + 0.020*\"크림\" + 0.020*\"여름\" + 0.019*\"사용\" + 0.019*\"건성\" + 0.018*\"흡수\" + 0.018*\"느낌\" + 0.018*\"추천\" + 0.016*\"보습력\" + 0.016*\"쓰기\" + 0.015*\"제품\" + 0.015*\"복합성\" + 0.015*\"자극\" + 0.013*\"트러블\" + 0.013*\"수부지\" + 0.013*\"얼굴\"\n",
      "Topic: 5 Word: 0.026*\"엄마\" + 0.020*\"주름\" + 0.020*\"효과\" + 0.018*\"사용\" + 0.016*\"제품\" + 0.015*\"선물\" + 0.015*\"구매\" + 0.014*\"크림\" + 0.014*\"재생크림\" + 0.013*\"체험단\" + 0.012*\"느낌\" + 0.012*\"피부\" + 0.012*\"성분\" + 0.011*\"생각\" + 0.011*\"스틱\" + 0.011*\"개선\" + 0.010*\"부분\" + 0.010*\"비타민\" + 0.010*\"지성\" + 0.009*\"브랜드\"\n",
      "topic_num: 6, no_above: 0.6\n",
      "0.5174139641356046\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in grid_search[15]['model'].print_topics(-1,num_words=20):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "print('topic_num: {}, no_above: {}'.format(grid_search[15]['topic_num'], grid_search[15]['no_above']))\n",
    "print(grid_search[15]['co_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search[15]['model'].alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667, 0.16666667], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search[15]['model'].eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.1,0.2,0.3]\n",
    "eta = [0.1,0.2,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46444230620032656\n",
      "0.46750659586211635\n",
      "0.46837837174010005\n",
      "0.46982771553843056\n",
      "0.47299167405183484\n",
      "0.4770056468957365\n",
      "0.48401796088429977\n",
      "0.4885575323712058\n",
      "0.4962734457619359\n",
      "0.5012565686905393\n",
      "0.5092296872895778\n",
      "0.5098363545248776\n",
      "0.5122635747309897\n",
      "0.5204864872125491\n",
      "0.5260638329496837\n"
     ]
    }
   ],
   "source": [
    "max_co = 0\n",
    "max_idx= 0\n",
    "\n",
    "for a in above_param:\n",
    "    dictionary = corpora.Dictionary(oily_list)\n",
    "    dictionary.filter_extremes(no_below=50, no_above=a)\n",
    "    bow_corpus = [dictionary.doc2bow(text) for text in oily_list]\n",
    "        \n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "    \n",
    "    for t in topic_param:\n",
    "        for al in alpha:\n",
    "            for et in eta:\n",
    "                set={}\n",
    "                lda_model_tfidf = gensim.models.LdaMulticore(corpus=corpus_tfidf, num_topics=t, id2word=dictionary, passes=20, iterations=100, chunksize=394, alpha=al, eta=et, random_state=42)\n",
    "                coherencemodel = CoherenceModel(model=lda_model_tfidf, texts=oily_list, dictionary=dictionary, coherence='c_v')\n",
    "                co_val = coherencemodel.get_coherence()\n",
    "\n",
    "                set[\"no_above\"] = a\n",
    "                set[\"model\"] = lda_model_tfidf\n",
    "                set[\"topic_num\"] = t\n",
    "                set[\"alpha\"] = al\n",
    "                set[\"eta\"] = et\n",
    "                set[\"co_val\"] = co_val\n",
    "\n",
    "                grid_search2.append(set)\n",
    "\n",
    "                if co_val > max_co:\n",
    "                    max_co = co_val\n",
    "                    print (max_co)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df2 = pd.DataFrame(grid_search2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_above</th>\n",
       "      <th>model</th>\n",
       "      <th>topic_num</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>co_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.526064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=5, decay=0....</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.523836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.523836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.6</td>\n",
       "      <td>LdaModel(num_terms=277, num_topics=5, decay=0....</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.521434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.5</td>\n",
       "      <td>LdaModel(num_terms=276, num_topics=9, decay=0....</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.520486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=8, decay=0....</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.454064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.454001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.453819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=4, decay=0....</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.452117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.4</td>\n",
       "      <td>LdaModel(num_terms=272, num_topics=8, decay=0....</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.451547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no_above                                              model  topic_num  \\\n",
       "108       0.6  LdaModel(num_terms=277, num_topics=4, decay=0....          4   \n",
       "117       0.6  LdaModel(num_terms=277, num_topics=5, decay=0....          5   \n",
       "113       0.6  LdaModel(num_terms=277, num_topics=4, decay=0....          4   \n",
       "119       0.6  LdaModel(num_terms=277, num_topics=5, decay=0....          5   \n",
       "99        0.5  LdaModel(num_terms=276, num_topics=9, decay=0....          9   \n",
       "..        ...                                                ...        ...   \n",
       "42        0.4  LdaModel(num_terms=272, num_topics=8, decay=0....          8   \n",
       "8         0.4  LdaModel(num_terms=272, num_topics=4, decay=0....          4   \n",
       "7         0.4  LdaModel(num_terms=272, num_topics=4, decay=0....          4   \n",
       "6         0.4  LdaModel(num_terms=272, num_topics=4, decay=0....          4   \n",
       "43        0.4  LdaModel(num_terms=272, num_topics=8, decay=0....          8   \n",
       "\n",
       "     alpha  eta    co_val  \n",
       "108    0.1  0.1  0.526064  \n",
       "117    0.1  0.1  0.523836  \n",
       "113    0.2  0.3  0.523836  \n",
       "119    0.1  0.3  0.521434  \n",
       "99     0.1  0.1  0.520486  \n",
       "..     ...  ...       ...  \n",
       "42     0.3  0.1  0.454064  \n",
       "8      0.3  0.3  0.454001  \n",
       "7      0.3  0.2  0.453819  \n",
       "6      0.3  0.1  0.452117  \n",
       "43     0.3  0.2  0.451547  \n",
       "\n",
       "[162 rows x 6 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df2.sort_values(by='co_val', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.026*\"크림\" + 0.024*\"톤업\" + 0.019*\"구매\" + 0.017*\"사용\" + 0.017*\"제품\" + 0.017*\"피부\" + 0.015*\"앰플\" + 0.015*\"마스크\" + 0.013*\"느낌\" + 0.013*\"트러블\" + 0.012*\"진정효과\" + 0.011*\"탄력\" + 0.011*\"효과\" + 0.011*\"지성\" + 0.010*\"성분\" + 0.010*\"라인\" + 0.010*\"요즘\" + 0.010*\"자연\" + 0.009*\"처음\" + 0.009*\"좋아서\"\n",
      "Topic: 1 Word: 0.025*\"피부\" + 0.020*\"지성\" + 0.019*\"보습\" + 0.018*\"여드름\" + 0.018*\"크림\" + 0.018*\"자극\" + 0.018*\"제품\" + 0.017*\"사용\" + 0.015*\"트러블\" + 0.015*\"진정\" + 0.015*\"느낌\" + 0.013*\"건성\" + 0.013*\"흡수\" + 0.013*\"추천\" + 0.012*\"구매\" + 0.012*\"얼굴\" + 0.012*\"만족\" + 0.011*\"건조\" + 0.011*\"보습력\" + 0.011*\"효과\"\n",
      "Topic: 2 Word: 0.017*\"제품\" + 0.017*\"세일\" + 0.017*\"겨울\" + 0.017*\"사용\" + 0.017*\"구매\" + 0.017*\"가격\" + 0.016*\"수분크림\" + 0.016*\"크림\" + 0.015*\"추천\" + 0.014*\"튜브\" + 0.014*\"쓰기\" + 0.013*\"피부\" + 0.013*\"닥터\" + 0.013*\"여름\" + 0.012*\"보습\" + 0.012*\"지성\" + 0.012*\"느낌\" + 0.011*\"건조\" + 0.011*\"할인\" + 0.011*\"생각\"\n",
      "Topic: 3 Word: 0.019*\"제품\" + 0.019*\"사용\" + 0.017*\"크림\" + 0.016*\"느낌\" + 0.016*\"수분\" + 0.014*\"피부\" + 0.014*\"엄마\" + 0.013*\"수분크림\" + 0.013*\"지성\" + 0.012*\"수부지\" + 0.012*\"구매\" + 0.012*\"건조\" + 0.010*\"얼굴\" + 0.010*\"흡수\" + 0.010*\"타입\" + 0.010*\"생각\" + 0.010*\"젤크림\" + 0.010*\"부분\" + 0.009*\"건성\" + 0.009*\"마무리\"\n",
      "topic_num: 4, no_above: 0.6, alpha: 0.1, eta: 0.1\n",
      "0.5260638329496837\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in grid_search2[108]['model'].print_topics(-1,num_words=20):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "print('topic_num: {}, no_above: {}, alpha: {}, eta: {}'.format(grid_search2[108]['topic_num'], grid_search2[108]['no_above'], grid_search2[108]['alpha'],grid_search2[108]['eta']))\n",
    "print(grid_search2[108]['co_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
